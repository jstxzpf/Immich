#!/usr/bin/env python3
"""
Immichç…§ç‰‡æŠ€æœ¯è§„æ ¼å·®å¼‚åˆ†æè„šæœ¬
ç”¨äºåˆ†æ2011å¹´å‰åç…§ç‰‡çš„æŠ€æœ¯å·®å¼‚ï¼Œæ‰¾å‡ºå½±å“äººè„¸æ£€æµ‹çš„å…³é”®å› ç´ 
"""

import os
import sys
import json
import requests
from datetime import datetime
from pathlib import Path
from PIL import Image, ExifTags
from PIL.ExifTags import TAGS
import numpy as np

# é…ç½®
IMMICH_SERVER = "http://10.132.60.111:2283"
SAMPLE_SIZE = 10  # æ¯ä¸ªå¹´ä»£é‡‡æ ·çš„ç…§ç‰‡æ•°é‡

def get_image_metadata(image_path):
    """è·å–å›¾ç‰‡çš„è¯¦ç»†å…ƒæ•°æ®"""
    try:
        with Image.open(image_path) as img:
            # åŸºæœ¬ä¿¡æ¯
            metadata = {
                'filename': os.path.basename(image_path),
                'format': img.format,
                'mode': img.mode,
                'size': img.size,
                'width': img.width,
                'height': img.height,
                'resolution': img.width * img.height,
                'aspect_ratio': round(img.width / img.height, 2),
                'has_transparency': img.mode in ('RGBA', 'LA') or 'transparency' in img.info,
            }
            
            # EXIFæ•°æ®
            exif_data = {}
            if hasattr(img, '_getexif') and img._getexif() is not None:
                exif = img._getexif()
                for tag_id, value in exif.items():
                    tag = TAGS.get(tag_id, tag_id)
                    exif_data[tag] = str(value)
            
            metadata['exif'] = exif_data
            
            # è‰²å½©ä¿¡æ¯
            if img.mode == 'RGB':
                img_array = np.array(img)
                metadata['color_stats'] = {
                    'mean_brightness': float(np.mean(img_array)),
                    'std_brightness': float(np.std(img_array)),
                    'mean_r': float(np.mean(img_array[:,:,0])),
                    'mean_g': float(np.mean(img_array[:,:,1])),
                    'mean_b': float(np.mean(img_array[:,:,2])),
                }
            
            return metadata
            
    except Exception as e:
        print(f"Error processing {image_path}: {e}")
        return None

def analyze_photos_by_year(photo_dir):
    """æŒ‰å¹´ä»½åˆ†æç…§ç‰‡"""
    photo_dir = Path(photo_dir)
    if not photo_dir.exists():
        print(f"ç…§ç‰‡ç›®å½•ä¸å­˜åœ¨: {photo_dir}")
        return None
    
    # æ”¶é›†ç…§ç‰‡æ–‡ä»¶
    photo_files = []
    for ext in ['*.jpg', '*.jpeg', '*.JPG', '*.JPEG']:
        photo_files.extend(photo_dir.rglob(ext))
    
    print(f"æ‰¾åˆ° {len(photo_files)} å¼ ç…§ç‰‡")
    
    # æŒ‰å¹´ä»½åˆ†ç»„
    photos_by_year = {}
    for photo_path in photo_files:
        try:
            # å°è¯•ä»æ–‡ä»¶åæˆ–EXIFè·å–å¹´ä»½
            year = None
            
            # æ–¹æ³•1: ä»EXIFè·å–
            try:
                with Image.open(photo_path) as img:
                    if hasattr(img, '_getexif') and img._getexif() is not None:
                        exif = img._getexif()
                        for tag_id, value in exif.items():
                            tag = TAGS.get(tag_id, tag_id)
                            if tag == 'DateTime':
                                year = int(str(value)[:4])
                                break
            except:
                pass
            
            # æ–¹æ³•2: ä»æ–‡ä»¶ä¿®æ”¹æ—¶é—´è·å–
            if year is None:
                mtime = os.path.getmtime(photo_path)
                year = datetime.fromtimestamp(mtime).year
            
            if year not in photos_by_year:
                photos_by_year[year] = []
            photos_by_year[year].append(photo_path)
            
        except Exception as e:
            print(f"å¤„ç†ç…§ç‰‡æ—¶å‡ºé”™ {photo_path}: {e}")
            continue
    
    return photos_by_year

def compare_photo_groups(photos_by_year):
    """å¯¹æ¯”ä¸åŒå¹´ä»½ç…§ç‰‡çš„æŠ€æœ¯è§„æ ¼"""
    
    # åˆ†ä¸ºä¸¤ç»„ï¼š2011å¹´åŠä»¥å‰ vs 2012å¹´åŠä»¥å
    old_photos = []  # 2011å¹´åŠä»¥å‰
    new_photos = []  # 2012å¹´åŠä»¥å
    
    for year, photos in photos_by_year.items():
        if year <= 2011:
            old_photos.extend(photos[:SAMPLE_SIZE])  # é™åˆ¶é‡‡æ ·æ•°é‡
        elif year >= 2012:
            new_photos.extend(photos[:SAMPLE_SIZE])  # é™åˆ¶é‡‡æ ·æ•°é‡
    
    print(f"è€ç…§ç‰‡æ ·æœ¬: {len(old_photos)} å¼  (2011å¹´åŠä»¥å‰)")
    print(f"æ–°ç…§ç‰‡æ ·æœ¬: {len(new_photos)} å¼  (2012å¹´åŠä»¥å)")
    
    # åˆ†æä¸¤ç»„ç…§ç‰‡
    old_metadata = []
    new_metadata = []
    
    print("\nåˆ†æè€ç…§ç‰‡...")
    for i, photo_path in enumerate(old_photos[:SAMPLE_SIZE]):
        print(f"  å¤„ç† {i+1}/{min(len(old_photos), SAMPLE_SIZE)}: {photo_path.name}")
        metadata = get_image_metadata(photo_path)
        if metadata:
            old_metadata.append(metadata)
    
    print("\nåˆ†ææ–°ç…§ç‰‡...")
    for i, photo_path in enumerate(new_photos[:SAMPLE_SIZE]):
        print(f"  å¤„ç† {i+1}/{min(len(new_photos), SAMPLE_SIZE)}: {photo_path.name}")
        metadata = get_image_metadata(photo_path)
        if metadata:
            new_metadata.append(metadata)
    
    return old_metadata, new_metadata

def generate_comparison_report(old_metadata, new_metadata):
    """ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š"""
    
    def calculate_stats(metadata_list, field):
        """è®¡ç®—ç»Ÿè®¡æ•°æ®"""
        values = []
        for item in metadata_list:
            if field in item and item[field] is not None:
                values.append(item[field])
        
        if not values:
            return None
        
        return {
            'count': len(values),
            'min': min(values),
            'max': max(values),
            'avg': sum(values) / len(values),
            'median': sorted(values)[len(values)//2]
        }
    
    print("\n" + "="*60)
    print("ç…§ç‰‡æŠ€æœ¯è§„æ ¼å¯¹æ¯”æŠ¥å‘Š")
    print("="*60)
    
    # åˆ†è¾¨ç‡å¯¹æ¯”
    print("\nğŸ“ åˆ†è¾¨ç‡å¯¹æ¯”:")
    old_res = calculate_stats(old_metadata, 'resolution')
    new_res = calculate_stats(new_metadata, 'resolution')
    
    if old_res and new_res:
        print(f"  è€ç…§ç‰‡å¹³å‡åˆ†è¾¨ç‡: {old_res['avg']:,.0f} åƒç´ ")
        print(f"  æ–°ç…§ç‰‡å¹³å‡åˆ†è¾¨ç‡: {new_res['avg']:,.0f} åƒç´ ")
        print(f"  åˆ†è¾¨ç‡æå‡: {(new_res['avg']/old_res['avg']-1)*100:.1f}%")
    
    # å°ºå¯¸å¯¹æ¯”
    print("\nğŸ“ å°ºå¯¸å¯¹æ¯”:")
    old_width = calculate_stats(old_metadata, 'width')
    new_width = calculate_stats(new_metadata, 'width')
    old_height = calculate_stats(old_metadata, 'height')
    new_height = calculate_stats(new_metadata, 'height')
    
    if all([old_width, new_width, old_height, new_height]):
        print(f"  è€ç…§ç‰‡å¹³å‡å°ºå¯¸: {old_width['avg']:.0f} x {old_height['avg']:.0f}")
        print(f"  æ–°ç…§ç‰‡å¹³å‡å°ºå¯¸: {new_width['avg']:.0f} x {new_height['avg']:.0f}")
    
    # æ ¼å¼å¯¹æ¯”
    print("\nğŸ¨ æ ¼å¼å¯¹æ¯”:")
    old_formats = {}
    new_formats = {}
    
    for item in old_metadata:
        fmt = item.get('format', 'Unknown')
        old_formats[fmt] = old_formats.get(fmt, 0) + 1
    
    for item in new_metadata:
        fmt = item.get('format', 'Unknown')
        new_formats[fmt] = new_formats.get(fmt, 0) + 1
    
    print(f"  è€ç…§ç‰‡æ ¼å¼åˆ†å¸ƒ: {old_formats}")
    print(f"  æ–°ç…§ç‰‡æ ¼å¼åˆ†å¸ƒ: {new_formats}")
    
    # è‰²å½©æ¨¡å¼å¯¹æ¯”
    print("\nğŸŒˆ è‰²å½©æ¨¡å¼å¯¹æ¯”:")
    old_modes = {}
    new_modes = {}
    
    for item in old_metadata:
        mode = item.get('mode', 'Unknown')
        old_modes[mode] = old_modes.get(mode, 0) + 1
    
    for item in new_metadata:
        mode = item.get('mode', 'Unknown')
        new_modes[mode] = new_modes.get(mode, 0) + 1
    
    print(f"  è€ç…§ç‰‡è‰²å½©æ¨¡å¼: {old_modes}")
    print(f"  æ–°ç…§ç‰‡è‰²å½©æ¨¡å¼: {new_modes}")
    
    # EXIFæ•°æ®å¯¹æ¯”
    print("\nğŸ“‹ EXIFæ•°æ®å¯¹æ¯”:")
    old_exif_keys = set()
    new_exif_keys = set()
    
    for item in old_metadata:
        old_exif_keys.update(item.get('exif', {}).keys())
    
    for item in new_metadata:
        new_exif_keys.update(item.get('exif', {}).keys())
    
    print(f"  è€ç…§ç‰‡EXIFå­—æ®µæ•°: {len(old_exif_keys)}")
    print(f"  æ–°ç…§ç‰‡EXIFå­—æ®µæ•°: {len(new_exif_keys)}")
    print(f"  æ–°å¢EXIFå­—æ®µ: {new_exif_keys - old_exif_keys}")
    
    # å…³é”®å‘ç°
    print("\nğŸ” å…³é”®å‘ç°:")
    if new_res and old_res and new_res['avg'] > old_res['avg'] * 1.5:
        print("  âš ï¸  æ–°ç…§ç‰‡åˆ†è¾¨ç‡æ˜¾è‘—æé«˜ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´æ£€æµ‹å‚æ•°")
    
    if 'JPEG' in new_formats and 'JPEG' in old_formats:
        print("  âœ… æ–°è€ç…§ç‰‡éƒ½ä½¿ç”¨JPEGæ ¼å¼ï¼Œæ ¼å¼å…¼å®¹æ€§è‰¯å¥½")
    
    print("\nğŸ’¡ å»ºè®®:")
    print("  1. å·²å°†æ£€æµ‹é˜ˆå€¼ä»0.7é™ä½åˆ°0.3ï¼Œåº”è¯¥èƒ½æé«˜æ£€æµ‹ç‡")
    print("  2. å¦‚æœé—®é¢˜ä»ç„¶å­˜åœ¨ï¼Œè€ƒè™‘é’ˆå¯¹é«˜åˆ†è¾¨ç‡ç…§ç‰‡ä¼˜åŒ–é¢„å¤„ç†")
    print("  3. å¯èƒ½éœ€è¦è°ƒæ•´RetinaFaceçš„input_sizeå‚æ•°")

def main():
    """ä¸»å‡½æ•°"""
    print("Immichç…§ç‰‡æŠ€æœ¯è§„æ ¼å·®å¼‚åˆ†æ")
    print("="*40)
    
    # ç…§ç‰‡ç›®å½•
    photo_dir = "/data/cleanjpg"
    
    if not os.path.exists(photo_dir):
        print(f"é”™è¯¯: ç…§ç‰‡ç›®å½•ä¸å­˜åœ¨ {photo_dir}")
        print("è¯·ç¡®è®¤ç…§ç‰‡ç›®å½•è·¯å¾„æ˜¯å¦æ­£ç¡®")
        return
    
    # åˆ†æç…§ç‰‡
    print(f"åˆ†æç…§ç‰‡ç›®å½•: {photo_dir}")
    photos_by_year = analyze_photos_by_year(photo_dir)
    
    if not photos_by_year:
        print("æœªæ‰¾åˆ°ç…§ç‰‡æ–‡ä»¶")
        return
    
    print(f"\næŒ‰å¹´ä»½åˆ†å¸ƒ:")
    for year in sorted(photos_by_year.keys()):
        print(f"  {year}å¹´: {len(photos_by_year[year])} å¼ ")
    
    # å¯¹æ¯”åˆ†æ
    old_metadata, new_metadata = compare_photo_groups(photos_by_year)
    
    if not old_metadata or not new_metadata:
        print("è­¦å‘Š: ç¼ºå°‘è¶³å¤Ÿçš„æ ·æœ¬æ•°æ®è¿›è¡Œå¯¹æ¯”")
        return
    
    # ç”ŸæˆæŠ¥å‘Š
    generate_comparison_report(old_metadata, new_metadata)
    
    # ä¿å­˜è¯¦ç»†æ•°æ®
    report_data = {
        'timestamp': datetime.now().isoformat(),
        'old_photos_metadata': old_metadata,
        'new_photos_metadata': new_metadata,
        'summary': {
            'old_photos_count': len(old_metadata),
            'new_photos_count': len(new_metadata),
            'detection_threshold_changed': True,
            'old_threshold': 0.7,
            'new_threshold': 0.3
        }
    }
    
    with open('photo_analysis_report.json', 'w', encoding='utf-8') as f:
        json.dump(report_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: photo_analysis_report.json")

if __name__ == "__main__":
    main()
